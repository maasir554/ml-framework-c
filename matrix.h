
#ifndef MATRIX_H
#define MATRIX_H

#include "base.h"
#include "arena.h"

typedef struct{
    u32 rows, cols;
    f32* data;
} matrix;

/*
    
# Mathematical functions to deal with matrix computations

- in production codebase, the following are the very functions which will run on the GPU
- however, for the current implementation of the project, I am going to run them on CPU for simplicity
- with that said, may be in the future implementations, I will try using GPU api's for the definition of these functions.

*/

// production framworks use tensors, which are n-dimantional arrays,
// but this project, we are going with 2-dimentional arrays.

matrix* mat_create(mem_arena* arena, u32 rows, u32 cols);
void mat_copy(matrix* dest, matrix* src);
void mat_clear(matrix* mat);
void mat_fill(matrix* mat, f32 x);
void mat_scale(matrix* mat, f32 scale);

b32 mat_add(matrix* out, const matrix* a, const matrix* b);
b32 mat_sub(matrix* out, const matrix* a, const matrix* b);
b32 mat_mul(
    matrix* out, const matrix* s, const matrix* b, 
    b8 zero_out, b8 transpose_a, b8 transpose_b
);

b32 mat_relu(matrix* out, const matrix* in); //ReLU: Rectified Linear Unit 0 if x <= 0 else x
b32 mat_softmax(matrix* out, const matrix* in); // converts input vector to prob. distribution

b32 mat_cross_entropy(matrix* out, const matrix* p, const matrix* q); // cost function
// cross entropy loss is generally good for dealing with prob. distrib. generated by softmax
// p-> expected probability distrib., q -> actual probability distrib.

b32 mat_relu_add_grad(matrix* out, const matrix* in); // add the gradient of relu to accumulated grad.
b32 mat_softmax_add_grad(matrix* out, const matrix* in); // ... of softmax to ...
b32 mat_cross_entropy_add_grad(matrix* out, const matrix* p, const matrix* q); // ... of cross entropy to ...

#endif
